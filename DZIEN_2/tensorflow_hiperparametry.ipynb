{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    "!pip install keras-tuner"
   ],
   "execution_count":1,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Collecting keras-tuner\r\n",
      "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0\/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9\/128.9 kB\u001b[0m \u001b[31m18.1 MB\/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: keras in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from keras-tuner) (2.10.0)\r\n",
      "Requirement already satisfied: packaging in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from keras-tuner) (23.2)\r\n",
      "Requirement already satisfied: requests in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from keras-tuner) (2.30.0)\r\n",
      "Collecting kt-legacy (from keras-tuner)\r\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests->keras-tuner) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests->keras-tuner) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests->keras-tuner) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests->keras-tuner) (2023.11.17)\r\n",
      "Installing collected packages: kt-legacy, keras-tuner\r\n",
      "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"c80wsHLb29gGPWi16Eujqz",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras_tuner.tuners import RandomSearch"
   ],
   "execution_count":2,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"MApsBa0gNhspko8C236Luk",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#zdefiniowanie modelu\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers',min_value=1,max_value=3)):\n",
    "        model.add(layers.Flatten(input_shape=(28,28)))\n",
    "        model.add(layers.Dense(units=hp.Int('units_'+str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=512,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    model.add(layers.Dense(10,activation='softmax'))\n",
    "    model.compile(optimizer=keras.optimizers.Adam(\n",
    "        hp.Choice('learning_rate',\n",
    "                  values=[1e-2,1e-3,1e-4])),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ],
   "execution_count":7,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"A8riN1JAkTUxyekJRi7Yju",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#inicjalizacja strojenia hiperparametrów\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='myparams'\n",
    ")"
   ],
   "execution_count":8,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Reloading Tuner from my_dir\/myparams\/tuner0.json\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"rzJxImQ6aCyjIafik8rRI8",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train,x_test = x_train\/255.0,x_test\/255.0"
   ],
   "execution_count":9,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"zx5JYURhWFkuTHtQg7bS1V",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "tuner.search(x_train,y_train,\n",
    "             epochs=5,\n",
    "             validation_data=(x_test,y_test))"
   ],
   "execution_count":10,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Trial 5 Complete [00h 05m 40s]\n",
      "val_accuracy: 0.9419333140055338\n",
      "\n",
      "Best val_accuracy So Far: 0.9746333360671997\n",
      "Total elapsed time: 00h 19m 16s\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"j3oofmr5tBpTGGwjkR1dAU",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "tuner.results_summary()"
   ],
   "execution_count":11,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Results summary\n",
      "Results in my_dir\/myparams\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 96\n",
      "learning_rate: 0.001\n",
      "units_1: 192\n",
      "units_2: 480\n",
      "units_3: 352\n",
      "Score: 0.9746333360671997\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 160\n",
      "learning_rate: 0.0001\n",
      "units_1: 256\n",
      "units_2: 256\n",
      "units_3: 384\n",
      "Score: 0.9706999858220419\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "num_layers: 5\n",
      "units_0: 320\n",
      "learning_rate: 0.01\n",
      "units_1: 416\n",
      "units_2: 128\n",
      "units_3: 288\n",
      "units_4: 32\n",
      "Score: 0.9419333140055338\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 480\n",
      "learning_rate: 0.0001\n",
      "units_1: 32\n",
      "units_2: 32\n",
      "units_3: 32\n",
      "Traceback (most recent call last):\n",
      "  File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras_tuner\/src\/engine\/base_tuner.py\", line 273, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras_tuner\/src\/engine\/base_tuner.py\", line 238, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras_tuner\/src\/engine\/tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras_tuner\/src\/engine\/tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "  File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras_tuner\/src\/engine\/hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "  File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/utils\/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"\/tmp\/__autograph_generated_filercgtx3ro.py\", line 15, in tf__train_function\n",
      "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/engine\/training.py\", line 1160, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/engine\/training.py\", line 1146, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/engine\/training.py\", line 1135, in run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/engine\/training.py\", line 994, in train_step\n",
      "        loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/engine\/training.py\", line 1052, in compute_loss\n",
      "        return self.compiled_loss(\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/engine\/compile_utils.py\", line 265, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/losses.py\", line 152, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/losses.py\", line 272, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/losses.py\", line 2084, in sparse_categorical_crossentropy\n",
      "        return backend.sparse_categorical_crossentropy(\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/backend.py\", line 5630, in sparse_categorical_crossentropy\n",
      "        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\n",
      "    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(896, 10)\n",
      "\n",
      "\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 288\n",
      "learning_rate: 0.0001\n",
      "units_1: 512\n",
      "units_2: 96\n",
      "units_3: 224\n",
      "Traceback (most recent call last):\n",
      "  File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras_tuner\/src\/engine\/base_tuner.py\", line 273, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras_tuner\/src\/engine\/base_tuner.py\", line 238, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras_tuner\/src\/engine\/tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras_tuner\/src\/engine\/tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "  File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras_tuner\/src\/engine\/hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "  File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/utils\/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"\/tmp\/__autograph_generated_filercgtx3ro.py\", line 15, in tf__train_function\n",
      "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/engine\/training.py\", line 1160, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/engine\/training.py\", line 1146, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/engine\/training.py\", line 1135, in run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/engine\/training.py\", line 994, in train_step\n",
      "        loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/engine\/training.py\", line 1052, in compute_loss\n",
      "        return self.compiled_loss(\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/engine\/compile_utils.py\", line 265, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/losses.py\", line 152, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/losses.py\", line 272, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/losses.py\", line 2084, in sparse_categorical_crossentropy\n",
      "        return backend.sparse_categorical_crossentropy(\n",
      "    File \"\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/keras\/backend.py\", line 5630, in sparse_categorical_crossentropy\n",
      "        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
      "\n",
      "    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(896, 10)\n",
      "\n",
      "\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"SXBWT4xlszK341DBSxIBaB",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "eval_loss,eval_accuracy = best_model.evaluate(x_test,y_test)\n",
    "print(f'Najlepszy model-> Loss: {eval_loss}, Accuracy: {eval_accuracy}')"
   ],
   "execution_count":12,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "\r  1\/313 [..............................] - ETA: 3:35 - loss: 0.0465 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  7\/313 [..............................] - ETA: 3s - loss: 0.0248 - accuracy: 0.9866  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 13\/313 [>.............................] - ETA: 3s - loss: 0.0546 - accuracy: 0.9760\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 21\/313 [=>............................] - ETA: 2s - loss: 0.0824 - accuracy: 0.9762\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 26\/313 [=>............................] - ETA: 2s - loss: 0.0889 - accuracy: 0.9724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 34\/313 [==>...........................] - ETA: 2s - loss: 0.0950 - accuracy: 0.9697\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 41\/313 [==>...........................] - ETA: 2s - loss: 0.1193 - accuracy: 0.9657\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 49\/313 [===>..........................] - ETA: 2s - loss: 0.1279 - accuracy: 0.9636\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 56\/313 [====>.........................] - ETA: 2s - loss: 0.1290 - accuracy: 0.9648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64\/313 [=====>........................] - ETA: 1s - loss: 0.1242 - accuracy: 0.9658\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 72\/313 [=====>........................] - ETA: 1s - loss: 0.1266 - accuracy: 0.9653\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 78\/313 [======>.......................] - ETA: 1s - loss: 0.1247 - accuracy: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 86\/313 [=======>......................] - ETA: 1s - loss: 0.1194 - accuracy: 0.9677\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 95\/313 [========>.....................] - ETA: 1s - loss: 0.1195 - accuracy: 0.9674\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r101\/313 [========>.....................] - ETA: 1s - loss: 0.1174 - accuracy: 0.9681\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r109\/313 [=========>....................] - ETA: 1s - loss: 0.1122 - accuracy: 0.9693\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r117\/313 [==========>...................] - ETA: 1s - loss: 0.1166 - accuracy: 0.9682\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125\/313 [==========>...................] - ETA: 1s - loss: 0.1196 - accuracy: 0.9672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r132\/313 [===========>..................] - ETA: 1s - loss: 0.1199 - accuracy: 0.9676\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r138\/313 [============>.................] - ETA: 1s - loss: 0.1187 - accuracy: 0.9676\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r146\/313 [============>.................] - ETA: 1s - loss: 0.1194 - accuracy: 0.9673\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r154\/313 [=============>................] - ETA: 1s - loss: 0.1186 - accuracy: 0.9671\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r161\/313 [==============>...............] - ETA: 1s - loss: 0.1153 - accuracy: 0.9674\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r169\/313 [===============>..............] - ETA: 1s - loss: 0.1103 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r175\/313 [===============>..............] - ETA: 1s - loss: 0.1077 - accuracy: 0.9696\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r180\/313 [================>.............] - ETA: 1s - loss: 0.1076 - accuracy: 0.9700\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r189\/313 [=================>............] - ETA: 0s - loss: 0.1047 - accuracy: 0.9702\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r194\/313 [=================>............] - ETA: 0s - loss: 0.1037 - accuracy: 0.9702\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r202\/313 [==================>...........] - ETA: 0s - loss: 0.1008 - accuracy: 0.9711\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r210\/313 [===================>..........] - ETA: 0s - loss: 0.1016 - accuracy: 0.9710\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r220\/313 [====================>.........] - ETA: 0s - loss: 0.0989 - accuracy: 0.9717\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r230\/313 [=====================>........] - ETA: 0s - loss: 0.0955 - accuracy: 0.9727\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r237\/313 [=====================>........] - ETA: 0s - loss: 0.0937 - accuracy: 0.9731\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r245\/313 [======================>.......] - ETA: 0s - loss: 0.0919 - accuracy: 0.9735\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r252\/313 [=======================>......] - ETA: 0s - loss: 0.0903 - accuracy: 0.9740\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r262\/313 [========================>.....] - ETA: 0s - loss: 0.0882 - accuracy: 0.9746\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r267\/313 [========================>.....] - ETA: 0s - loss: 0.0872 - accuracy: 0.9748\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r273\/313 [=========================>....] - ETA: 0s - loss: 0.0853 - accuracy: 0.9754\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r280\/313 [=========================>....] - ETA: 0s - loss: 0.0832 - accuracy: 0.9760\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r289\/313 [==========================>...] - ETA: 0s - loss: 0.0823 - accuracy: 0.9765\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r296\/313 [===========================>..] - ETA: 0s - loss: 0.0805 - accuracy: 0.9771\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r304\/313 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 0.9772\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r312\/313 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 0.9764\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r313\/313 [==============================] - 3s 7ms\/step - loss: 0.0834 - accuracy: 0.9764\n",
      "Najlepszy model-> Loss: 0.08335208147764206, Accuracy: 0.9764000177383423\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"6BYHuKoqimGvWnsvX8H6jf",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    
   ],
   "report_row_ids":[
    
   ],
   "version":3
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}